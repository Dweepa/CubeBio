{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import sys\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 978)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open('../Data/X_train_triplet', 'rb'))\n",
    "test = pickle.load(open('../Data/X_test_triplet', 'rb'))\n",
    "y = pickle.load(open('../Data/y_test', 'rb'))\n",
    "\n",
    "cov = pickle.load(open('../Data/covariance','rb'))\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class siamese:\n",
    "\n",
    "    # Create model\n",
    "    def __init__(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.x1 = tf.placeholder(tf.float32, [None, 978])\n",
    "        self.x2 = tf.placeholder(tf.float32, [None, 978])\n",
    "        self.x3 = tf.placeholder(tf.float32, [None, 978])\n",
    "        self.cov = tf.placeholder(tf.float32, [978,978])\n",
    "        with tf.variable_scope(\"siamese\") as scope:\n",
    "            self.o1 = self.network(self.x1)\n",
    "            scope.reuse_variables()\n",
    "            self.o2 = self.network(self.x2)\n",
    "            scope.reuse_variables()\n",
    "            self.o3 = self.network(self.x3)\n",
    "\n",
    "        self.loss = self.loss_with_cosine()\n",
    "\n",
    "    def network(self, x):\n",
    "        weights = []\n",
    "        fc1 = self.fc_layer(x, 1024, \"fc1\")\n",
    "        ac1 = tf.nn.relu(fc1)\n",
    "        fc2 = self.fc_layer(ac1, 1024, \"fc2\")\n",
    "        ac2 = tf.nn.relu(fc2)\n",
    "        fc3 = self.fc_layer(ac2, 32, \"fc3\")\n",
    "        fc3 = tf.nn.l2_normalize(fc3, axis=1)\n",
    "        return fc3\n",
    "\n",
    "    def fc_layer(self, bottom, n_weight, name):\n",
    "        assert len(bottom.get_shape()) == 2\n",
    "        n_prev_weight = bottom.get_shape()[1]\n",
    "        initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "        W = tf.get_variable(name+'W', dtype=tf.float32, shape=[n_prev_weight, n_weight], initializer=initer)\n",
    "        b = tf.get_variable(name+'b', dtype=tf.float32, initializer=tf.constant(0.01, shape=[n_weight], dtype=tf.float32))\n",
    "        fc = tf.nn.bias_add(tf.matmul(bottom, W), b)\n",
    "        return fc\n",
    "\n",
    "    def loss_with_euclid(self):  \n",
    "        eucd2 = tf.pow(tf.subtract(self.o1, self.o2), 2)\n",
    "        eucd2 = tf.sqrt(tf.reduce_sum(eucd2, axis=1))\n",
    "        eucd2_mean = tf.reduce_mean(eucd2, axis=0)\n",
    "        \n",
    "        eucd3 = tf.pow(tf.subtract(self.o1, self.o3), 2)\n",
    "        eucd3 = tf.sqrt(tf.reduce_sum(eucd3, axis=1))\n",
    "        eucd3_mean = tf.reduce_mean(eucd3, axis=0)\n",
    "        \n",
    "        return eucd2_mean, eucd3_mean, eucd2, eucd3\n",
    "    \n",
    "    def loss_with_cosine(self):  \n",
    "        eucd2 = tf.multiply(self.o1, self.o2)\n",
    "        eucd2 = 1-tf.pow(tf.reduce_sum(eucd2, axis=1), 2)\n",
    "        eucd2_mean = tf.reduce_mean(eucd2, axis=0)\n",
    "        \n",
    "        eucd3 = tf.multiply(self.o1, self.o3)\n",
    "        eucd3 = 1-tf.pow(tf.reduce_sum(eucd3, axis=1), 2)\n",
    "        eucd3_mean = tf.reduce_mean(eucd3, axis=0)\n",
    "        \n",
    "        return eucd2_mean, eucd3_mean, eucd2, eucd3\n",
    "    \n",
    "    def loss_with_mahalanobis(self):\n",
    "        m1 = mahalanobis(self.o1, self.o2, self.cov)\n",
    "        m2 = mahalanobis(self.o1, self.o3, self.cov)\n",
    "        return m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = siamese()\n",
    "optim_pos = tf.train.AdamOptimizer(0.005).minimize(s.loss[0])\n",
    "optim_neg = tf.train.AdamOptimizer(0.005).minimize(-s.loss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:  \n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    feed_dict={s.x1:X[0], s.x2:X[1], s.x3:X[2]}\n",
    "    \n",
    "    p_loss = []\n",
    "    n_loss = []\n",
    "    \n",
    "    for a in range(40):        \n",
    "        p_loss.append([])\n",
    "        n_loss.append([])\n",
    "        for b in range(len(X[0])):\n",
    "            sys.stdout.write('\\rEpoch %d:\\t%d/%d' % (a, b+1, len(X[0])))\n",
    "            feed_dict = {s.x1:X[0][b], s.x2:X[1][b], s.x3:X[2][b], s.cov=cov}\n",
    "            _, _, l = session.run([optim_pos, optim_neg, s.loss], feed_dict=feed_dict)\n",
    "            p_loss[-1].append(l[0])\n",
    "            n_loss[-1].append(l[1])\n",
    "        p_loss[-1] = sum(p_loss[-1])/len(p_loss[-1])\n",
    "        n_loss[-1] = sum(n_loss[-1])/len(n_loss[-1])\n",
    "        print(\" \", p_loss[-1], n_loss[-1]) \n",
    "    \n",
    "    embeddings = session.run([s.o1, s.o2, s.o3], feed_dict={s.x1:X[0], s.x2:X[1], s.x3:X[2],s.cov=cov})\n",
    "    trained = session.run([s.loss], feed_dict={s.x1:X[0], s.x2:X[1], s.x3:X[2],s.cov=cov})\n",
    "    pred = session.run([s.loss], feed_dict={s.x1:test[0], s.x2:test[1], s.x3:test[2],s.cov=cov})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(np.arange(40), p_loss, label='positive')\n",
    "plt.plot(np.arange(40), n_loss, label='negative')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in pred:\n",
    "    anch = normalize(i[0:16].reshape(1,-1)).flatten()\n",
    "    pos = normalize(i[16:32].reshape(1,-1)).flatten()\n",
    "    neg = normalize(i[32:].reshape(1,-1)).flatten()\n",
    "    pos_neg_val = [(np.dot(anch,pos)), (np.dot(anch,neg))]\n",
    "    print(pos_neg_val)\n",
    "    values.append(pos_neg_val[0]>=0.7)\n",
    "    values.append(pos_neg_val[1]<0.7)\n",
    "    # print(positives, negatives)\n",
    "    #     print(pos_val, neg_val, pos_val>neg_val)\n",
    "print((np.sum(np.asarray(values)==True))/len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.sum(trained[0][2]<=0.5)\n",
    "n = np.sum(trained[0][3]>0.5)\n",
    "print(p, n, (p+n)/420/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.sum(pred[0][2]<=0.5)\n",
    "n = np.sum(pred[0][3]>0.5)\n",
    "print(p, n, (p+n)/420/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 138\n",
    "print(trained[0][2][x], trained[0][3][x])\n",
    "print(embeddings[0][x], embeddings[1][x], embeddings[2][x], sep='\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './doc2vec_model.doc2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d7a2293cd4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./doc2vec_model.doc2vec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1474\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1475\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode should be a string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shortcut_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './doc2vec_model.doc2vec'"
     ]
    }
   ],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('./doc2vec_model.doc2vec', binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
