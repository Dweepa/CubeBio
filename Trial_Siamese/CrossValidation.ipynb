{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Import custom modules\n",
    "from network import *\n",
    "from data import *\n",
    "\n",
    "dbfile = open('../Data/full', 'rb')\n",
    "data = pickle.load(dbfile)\n",
    "dbfile = open('../Data/location_pert', 'rb')\n",
    "location_pert = pickle.load(dbfile)\n",
    "dbfile = open('../Data/pert2profiles', 'rb')\n",
    "pert2profiles = pickle.load(dbfile)\n",
    "dbfile = open('../Data/test_perts', 'rb')\n",
    "test_pert = pickle.load(dbfile)\n",
    "dbfile = open('../Data/train_perts', 'rb')\n",
    "train_pert = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "# X_train = generate_data(data,train_pert,100)\n",
    "# X_test = generate_data(data,test_pert,100)\n",
    "\n",
    "# dbfile = open('X_train_triplet_full', 'ab')\n",
    "# pickle.dump(X_train, dbfile)\n",
    "# dbfile.close()\n",
    "\n",
    "\n",
    "#X = pickle.load(open('../Data/X_train_triplet_full', 'rb'))\n",
    "#test = pickle.load(open('../Data/X_test_triplet_full', 'rb'))\n",
    "# y = pickle.load(open('../Data/y_test', 'rb'))\n",
    "\n",
    "# cross validation code WIP\n",
    "all_pert = np.concatenate((train_pert, test_pert))\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation run # 1\n",
      "(1736,) (434,)\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "WARNING:tensorflow:From /Users/dweepa/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t2/2\t0.266\t0.407\t\t75.000\t0.000\n",
      "Epoch 1:\t2/2\t0.567\t0.615\t\t75.000\t0.000\n",
      "Epoch 2:\t2/2\t0.411\t0.813\t\t75.000\t25.000\n",
      "Epoch 3:\t2/2\t0.416\t0.927\t\t75.000\t25.000\n",
      "Epoch 4:\t2/2\t0.359\t0.916\t\t75.000\t25.000\n",
      "Epoch 5:\t2/2\t0.306\t0.899\t\t75.000\t25.000\n",
      "Epoch 6:\t2/2\t0.265\t0.922\t\t100.000\t25.000\n",
      "Epoch 7:\t2/2\t0.201\t0.932\t\t100.000\t25.000\n",
      "Epoch 8:\t2/2\t0.144\t0.949\t\t100.000\t25.000\n",
      "Epoch 9:\t2/2\t0.103\t0.993\t\t100.000\t0.000\n",
      "\n",
      "Crossvalidation run # 2\n",
      "(1736,) (434,)\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t2/2\t0.195\t0.282\t\t75.000\t50.000\n",
      "Epoch 1:\t2/2\t0.625\t0.865\t\t75.000\t50.000\n",
      "Epoch 2:\t2/2\t0.451\t0.871\t\t75.000\t50.000\n",
      "Epoch 3:\t2/2\t0.246\t0.717\t\t75.000\t75.000\n",
      "Epoch 4:\t2/2\t0.123\t0.683\t\t75.000\t50.000\n",
      "Epoch 5:\t2/2\t0.049\t0.688\t\t75.000\t50.000\n",
      "Epoch 6:\t2/2\t0.021\t0.716\t\t100.000\t50.000\n",
      "Epoch 7:\t2/2\t0.013\t0.809\t\t100.000\t50.000\n",
      "Epoch 8:\t2/2\t0.010\t0.924\t\t100.000\t50.000\n",
      "Epoch 9:\t2/2\t0.009\t0.990\t\t100.000\t50.000\n",
      "\n",
      "Crossvalidation run # 3\n",
      "(1736,) (434,)\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t2/2\t0.344\t0.271\t\t25.000\t50.000\n",
      "Epoch 1:\t2/2\t0.604\t0.111\t\t75.000\t50.000\n",
      "Epoch 2:\t2/2\t0.133\t0.720\t\t100.000\t50.000\n",
      "Epoch 3:\t2/2\t0.166\t0.999\t\t100.000\t50.000\n",
      "Epoch 4:\t2/2\t0.055\t0.991\t\t100.000\t75.000\n",
      "Epoch 5:\t2/2\t0.023\t1.000\t\t100.000\t75.000\n",
      "Epoch 6:\t2/2\t0.022\t0.996\t\t100.000\t75.000\n",
      "Epoch 7:\t2/2\t0.017\t0.993\t\t100.000\t75.000\n",
      "Epoch 8:\t2/2\t0.011\t0.993\t\t100.000\t75.000\n",
      "Epoch 9:\t2/2\t0.005\t0.997\t\t100.000\t50.000\n",
      "\n",
      "Crossvalidation run # 4\n",
      "(1736,) (434,)\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t2/2\t0.320\t0.403\t\t75.000\t50.000\n",
      "Epoch 1:\t2/2\t0.239\t0.618\t\t100.000\t75.000\n",
      "Epoch 2:\t2/2\t0.350\t0.813\t\t100.000\t50.000\n",
      "Epoch 3:\t2/2\t0.068\t0.994\t\t100.000\t50.000\n",
      "Epoch 4:\t2/2\t0.011\t0.873\t\t100.000\t50.000\n",
      "Epoch 5:\t2/2\t0.004\t0.905\t\t100.000\t25.000\n",
      "Epoch 6:\t2/2\t0.003\t0.976\t\t100.000\t25.000\n",
      "Epoch 7:\t2/2\t0.003\t0.986\t\t100.000\t25.000\n",
      "Epoch 8:\t2/2\t0.003\t0.975\t\t100.000\t25.000\n",
      "Epoch 9:\t2/2\t0.002\t0.980\t\t100.000\t25.000\n",
      "\n",
      "Crossvalidation run # 5\n",
      "(1736,) (434,)\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "batch_size:  2\n",
      "2/2\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t2/2\t0.225\t0.192\t\t75.000\t50.000\n",
      "Epoch 1:\t2/2\t0.714\t0.733\t\t75.000\t25.000\n",
      "Epoch 2:\t2/2\t0.500\t0.973\t\t75.000\t50.000\n",
      "Epoch 3:\t2/2\t0.305\t0.972\t\t100.000\t50.000\n",
      "Epoch 4:\t2/2\t0.168\t0.979\t\t100.000\t25.000\n",
      "Epoch 5:\t2/2\t0.087\t0.942\t\t100.000\t25.000\n",
      "Epoch 6:\t2/2\t0.024\t0.978\t\t100.000\t50.000\n",
      "Epoch 7:\t2/2\t0.014\t0.933\t\t100.000\t25.000\n",
      "Epoch 8:\t2/2\t0.015\t0.967\t\t100.000\t25.000\n",
      "Epoch 9:\t2/2\t0.009\t0.969\t\t100.000\t25.000\n",
      "\n",
      "\n",
      "Cross-validation result: Train: 5.0\t\t Test:1.5\n"
     ]
    }
   ],
   "source": [
    "# cross validation code WIP\n",
    "all_pert = np.concatenate((train_pert,test_pert))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "def cross_validate(splitsize):\n",
    "    kf = KFold(n_splits=splitsize)\n",
    "    results = []\n",
    "    c=1\n",
    "    for train_idx, val_idx in kf.split(all_pert):\n",
    "        print(\"\\nCrossvalidation run #\",c)\n",
    "        c+=1\n",
    "        train_perts = all_pert[train_idx]\n",
    "        val_perts = all_pert[val_idx]\n",
    "        print(train_perts.shape,val_perts.shape)\n",
    "        X_train = generate_data(data,train_perts[0:2],1)\n",
    "        print(\"\\n\")\n",
    "        X_val = generate_data(data,val_perts[0:2],1)\n",
    "        s = siamese(\"cos\",\"net\")\n",
    "        epochs=10\n",
    "        print(\"\\n\")\n",
    "        embeddings, trained, pred, p_loss, n_loss, train_acc_l, test_acc_l = run_network(s, epochs, X_train, X_val)\n",
    "        \n",
    "        p = np.sum(trained[0][2]<=0.5)\n",
    "        n = np.sum(trained[0][3]>0.5)\n",
    "        train_acc = ((p+n)/len(X_train[0])/2)\n",
    "\n",
    "        p = np.sum(pred[0][2]<=0.5)\n",
    "        n = np.sum(pred[0][3]>0.5)\n",
    "        val_acc = ((p+n)/len(X_val[0])/2)\n",
    "        \n",
    "        accuracy = (train_acc, val_acc)\n",
    "        results.append(accuracy)\n",
    "    return results\n",
    "\n",
    "result = cross_validate(5)\n",
    "test_res=0\n",
    "train_res=0\n",
    "for i in result:\n",
    "    test_res+=i[1]\n",
    "    train_res+=i[0]\n",
    "print (\"\\n\\nCross-validation result: Train: \\n%s\\t\\t Test:%s\" % (train_res,test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
