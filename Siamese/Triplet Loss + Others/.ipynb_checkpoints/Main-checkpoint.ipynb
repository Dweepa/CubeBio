{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Import custom modules\n",
    "from network import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbfile = open('../../Data/full', 'rb')    \n",
    "data = pickle.load(dbfile)\n",
    "dbfile = open('../../Data/location_pert', 'rb')    \n",
    "location_pert = pickle.load(dbfile)\n",
    "dbfile = open('../../Data/pert2profiles', 'rb')    \n",
    "pert2profiles = pickle.load(dbfile)\n",
    "dbfile = open('../../Data/test_perts', 'rb')    \n",
    "test_pert = pickle.load(dbfile)\n",
    "dbfile = open('../../Data/train_perts', 'rb')    \n",
    "train_pert = pickle.load(dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  4200\n",
      "4200/4200"
     ]
    }
   ],
   "source": [
    "X_train = generate_data(data,train_pert[0:100],42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  4200\n",
      "1301/4200"
     ]
    }
   ],
   "source": [
    "X_test = generate_data(data,test_pert[0:100],42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the base network\n",
    "network = dict(n_dense=5, dense_units=16, activation='selu', dropout=AlphaDropout, dropout_rate=0.1,\n",
    "               kernel_initializer='lecun_normal', optimizer='sgd', num_classes=2)\n",
    "\n",
    "shared_model = create_base_network(**network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the siamese network\n",
    "model = create_siamese_network(shared_model)\n",
    "print(\"Siamese network model summary\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dum = np.zeros((len(X_train[0]),1))\n",
    "model.fit([X_train[0],X_train[1],X_train[2]],y_dum,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model.predict([X_test[0],X_test[1],X_test[2]])\n",
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([X_train[0],X_train[1],X_train[2]])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "anch = normalize(pred[0][0:16].reshape(1,-1)).flatten()\n",
    "pos = normalize(pred[0][16:32].reshape(1,-1)).flatten()\n",
    "neg = normalize(pred[0][32:].reshape(1,-1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_function(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in pred1:\n",
    "    anch = normalize(i[0:16].reshape(1,-1)).flatten()\n",
    "    pos = normalize(i[16:32].reshape(1,-1)).flatten()\n",
    "    neg = normalize(i[32:].reshape(1,-1)).flatten()\n",
    "    pos_neg_val = softmax_function([[np.abs(np.dot(anch,pos)), np.abs(np.dot(anch,neg))]]).flatten()\n",
    "    \n",
    "    #print(pos_neg_val)\n",
    "    values.append(pos_neg_val[0]>=0.5)\n",
    "    values.append(pos_neg_val[1]<0.5)\n",
    "# print(positives, negatives)\n",
    "#     print(pos_val, neg_val, pos_val>neg_val)\n",
    "print((np.sum(np.asarray(values)==True))/len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(anch,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dbfile = open('../../Data/X_train_triplet', 'ab')\n",
    "pickle.dump(X_train, dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dbfile = open('../../Data/X_test_triplet', 'ab')\n",
    "pickle.dump(X_test, dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
