{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"https://cdn.pixabay.com/photo/2016/12/07/09/45/dna-1889085__340.jpg\" width=10%> <h1> Application of AI to Discover Novel Binding of Small Molecules </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Sample Dataset for Testing Purposes\n",
    "\n",
    "##### Here we create a sample dataset for two reasons:\n",
    "- to get a better understanding of the structure of the data\n",
    "- test any sample code for validity\n",
    "\n",
    "##### Structure of sample dataset:\n",
    "1. A dataframe consisting of 50 genes and 1020 profiles [50 x 1020]\n",
    "2. Columns are a combination of drug, replicate, time, concentration, probe_location, cell type. For the purposes of this project only drug and replicate matters in terms of training. So the column name will be structured as\n",
    "\"*drug + replicate id + unique characters that represent time, concentration, probe_location and cell type*\"\n",
    "3. 20 columns consist of control genes or 'control probes'. Columns are labelled control_x where x is a number from 1 to 20\n",
    "3. Dataset consists of 25 drugs with 4 replicates and 10 combinations of time, concentration, probe_location and cell type\n",
    "\n",
    "| Feature      | Quantity | Represented By |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Drug      | 25       | Alphabets A-Y |\n",
    "| Replicate   | 4        | Numbers 1-4 |\n",
    "| Other features   | 10        | Random String of length 3 |\n",
    "\n",
    "***R_3_xcv*** represents a profile of drug 'R', of replicate 3, with other features coresponding to 'xcv'\n",
    "\n",
    "##### Construction of Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes = ['gene'+str(a) for a in range(50)]\n",
    "drugs = [chr(a) for a in range(65, 90)]\n",
    "replicates = [str(a) for a in range(1, 5)]\n",
    "other_features = set()\n",
    "\n",
    "while len(other_features)!=10:\n",
    "    rand_string = \"\". join([str(chr(int(random.random()*100)%26+97)) for a in range(3)])\n",
    "    other_features.add(rand_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"_\".join([a,b,c]) for a in drugs for b in replicates for c in other_features]\n",
    "# columns = [\"control_\"+str(a+1) for a in range(20)] + columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(2*np.random.rand(50, len(columns))-1, index=genes, columns=columns)\n",
    "data.columns = columns\n",
    "data.fillna(random.random(), inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_1_kky</th>\n",
       "      <th>A_1_yjn</th>\n",
       "      <th>A_1_ftu</th>\n",
       "      <th>A_1_qvc</th>\n",
       "      <th>A_1_lsf</th>\n",
       "      <th>A_1_ozh</th>\n",
       "      <th>A_1_ebc</th>\n",
       "      <th>A_1_toa</th>\n",
       "      <th>A_1_klb</th>\n",
       "      <th>A_1_ima</th>\n",
       "      <th>...</th>\n",
       "      <th>Y_4_kky</th>\n",
       "      <th>Y_4_yjn</th>\n",
       "      <th>Y_4_ftu</th>\n",
       "      <th>Y_4_qvc</th>\n",
       "      <th>Y_4_lsf</th>\n",
       "      <th>Y_4_ozh</th>\n",
       "      <th>Y_4_ebc</th>\n",
       "      <th>Y_4_toa</th>\n",
       "      <th>Y_4_klb</th>\n",
       "      <th>Y_4_ima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gene0</th>\n",
       "      <td>0.565431</td>\n",
       "      <td>0.454328</td>\n",
       "      <td>-0.997431</td>\n",
       "      <td>-0.147522</td>\n",
       "      <td>-0.266993</td>\n",
       "      <td>0.647802</td>\n",
       "      <td>0.327706</td>\n",
       "      <td>-0.782721</td>\n",
       "      <td>-0.251218</td>\n",
       "      <td>-0.253343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677855</td>\n",
       "      <td>-0.538512</td>\n",
       "      <td>-0.657175</td>\n",
       "      <td>-0.185452</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>-0.621859</td>\n",
       "      <td>-0.032930</td>\n",
       "      <td>0.802544</td>\n",
       "      <td>0.436068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene1</th>\n",
       "      <td>-0.339680</td>\n",
       "      <td>-0.703011</td>\n",
       "      <td>0.547694</td>\n",
       "      <td>-0.402608</td>\n",
       "      <td>0.303426</td>\n",
       "      <td>-0.064423</td>\n",
       "      <td>0.243335</td>\n",
       "      <td>0.967988</td>\n",
       "      <td>-0.375953</td>\n",
       "      <td>-0.889101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992498</td>\n",
       "      <td>0.673060</td>\n",
       "      <td>0.677454</td>\n",
       "      <td>-0.796117</td>\n",
       "      <td>-0.391574</td>\n",
       "      <td>-0.497911</td>\n",
       "      <td>0.977625</td>\n",
       "      <td>0.926948</td>\n",
       "      <td>-0.047017</td>\n",
       "      <td>-0.868945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene2</th>\n",
       "      <td>0.727901</td>\n",
       "      <td>-0.196407</td>\n",
       "      <td>-0.183411</td>\n",
       "      <td>-0.315536</td>\n",
       "      <td>0.898675</td>\n",
       "      <td>-0.309319</td>\n",
       "      <td>0.357032</td>\n",
       "      <td>-0.706039</td>\n",
       "      <td>0.548331</td>\n",
       "      <td>0.659212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559336</td>\n",
       "      <td>0.180941</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.430328</td>\n",
       "      <td>-0.716242</td>\n",
       "      <td>-0.871301</td>\n",
       "      <td>0.443298</td>\n",
       "      <td>0.431096</td>\n",
       "      <td>0.908664</td>\n",
       "      <td>0.866675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene3</th>\n",
       "      <td>0.156712</td>\n",
       "      <td>0.414263</td>\n",
       "      <td>-0.288991</td>\n",
       "      <td>-0.511516</td>\n",
       "      <td>0.776627</td>\n",
       "      <td>-0.032848</td>\n",
       "      <td>-0.478349</td>\n",
       "      <td>-0.809679</td>\n",
       "      <td>0.891934</td>\n",
       "      <td>0.771603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>-0.286369</td>\n",
       "      <td>-0.761032</td>\n",
       "      <td>-0.409968</td>\n",
       "      <td>0.562998</td>\n",
       "      <td>0.600992</td>\n",
       "      <td>0.058420</td>\n",
       "      <td>-0.533900</td>\n",
       "      <td>0.634965</td>\n",
       "      <td>0.371435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene4</th>\n",
       "      <td>0.567214</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.375861</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>-0.076705</td>\n",
       "      <td>0.385077</td>\n",
       "      <td>-0.640458</td>\n",
       "      <td>0.234052</td>\n",
       "      <td>-0.758381</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230065</td>\n",
       "      <td>0.690195</td>\n",
       "      <td>-0.107643</td>\n",
       "      <td>-0.132128</td>\n",
       "      <td>-0.290238</td>\n",
       "      <td>-0.240014</td>\n",
       "      <td>0.150119</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>-0.107498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A_1_kky   A_1_yjn   A_1_ftu   A_1_qvc   A_1_lsf   A_1_ozh   A_1_ebc  \\\n",
       "gene0  0.565431  0.454328 -0.997431 -0.147522 -0.266993  0.647802  0.327706   \n",
       "gene1 -0.339680 -0.703011  0.547694 -0.402608  0.303426 -0.064423  0.243335   \n",
       "gene2  0.727901 -0.196407 -0.183411 -0.315536  0.898675 -0.309319  0.357032   \n",
       "gene3  0.156712  0.414263 -0.288991 -0.511516  0.776627 -0.032848 -0.478349   \n",
       "gene4  0.567214 -0.212149 -0.375861  0.516339 -0.076705  0.385077 -0.640458   \n",
       "\n",
       "        A_1_toa   A_1_klb   A_1_ima    ...      Y_4_kky   Y_4_yjn   Y_4_ftu  \\\n",
       "gene0 -0.782721 -0.251218 -0.253343    ...     0.677855 -0.538512 -0.657175   \n",
       "gene1  0.967988 -0.375953 -0.889101    ...     0.992498  0.673060  0.677454   \n",
       "gene2 -0.706039  0.548331  0.659212    ...    -0.559336  0.180941  0.008483   \n",
       "gene3 -0.809679  0.891934  0.771603    ...     0.006165 -0.286369 -0.761032   \n",
       "gene4  0.234052 -0.758381  0.065517    ...    -0.230065  0.690195 -0.107643   \n",
       "\n",
       "        Y_4_qvc   Y_4_lsf   Y_4_ozh   Y_4_ebc   Y_4_toa   Y_4_klb   Y_4_ima  \n",
       "gene0 -0.185452  0.964592  0.125108 -0.621859 -0.032930  0.802544  0.436068  \n",
       "gene1 -0.796117 -0.391574 -0.497911  0.977625  0.926948 -0.047017 -0.868945  \n",
       "gene2  0.430328 -0.716242 -0.871301  0.443298  0.431096  0.908664  0.866675  \n",
       "gene3 -0.409968  0.562998  0.600992  0.058420 -0.533900  0.634965  0.371435  \n",
       "gene4 -0.132128 -0.290238 -0.240014  0.150119 -0.042335  0.998942 -0.107498  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifying Columns\n",
    "A label needs to be assigned to each class. This can be done at the biological replicate level or the perturbagen level. We create classifications for each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perturbagen_class = [int(a/25) for a in range(1000)]\n",
    "replicate_class = [10*a+c for a in range(25) for b in range(4) for c in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene0</th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>gene3</th>\n",
       "      <th>gene4</th>\n",
       "      <th>gene5</th>\n",
       "      <th>gene6</th>\n",
       "      <th>gene7</th>\n",
       "      <th>gene8</th>\n",
       "      <th>gene9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene40</th>\n",
       "      <th>gene41</th>\n",
       "      <th>gene42</th>\n",
       "      <th>gene43</th>\n",
       "      <th>gene44</th>\n",
       "      <th>gene45</th>\n",
       "      <th>gene46</th>\n",
       "      <th>gene47</th>\n",
       "      <th>gene48</th>\n",
       "      <th>gene49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A_1_kky</th>\n",
       "      <td>0.565431</td>\n",
       "      <td>-0.339680</td>\n",
       "      <td>0.727901</td>\n",
       "      <td>0.156712</td>\n",
       "      <td>0.567214</td>\n",
       "      <td>0.854648</td>\n",
       "      <td>-0.912212</td>\n",
       "      <td>0.109724</td>\n",
       "      <td>0.651533</td>\n",
       "      <td>0.056977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978305</td>\n",
       "      <td>-0.888512</td>\n",
       "      <td>-0.391051</td>\n",
       "      <td>-0.993740</td>\n",
       "      <td>-0.219221</td>\n",
       "      <td>0.131645</td>\n",
       "      <td>0.409954</td>\n",
       "      <td>-0.801225</td>\n",
       "      <td>-0.842967</td>\n",
       "      <td>0.366684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_yjn</th>\n",
       "      <td>0.454328</td>\n",
       "      <td>-0.703011</td>\n",
       "      <td>-0.196407</td>\n",
       "      <td>0.414263</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.475095</td>\n",
       "      <td>0.768395</td>\n",
       "      <td>0.798914</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673128</td>\n",
       "      <td>0.216370</td>\n",
       "      <td>0.264719</td>\n",
       "      <td>0.843114</td>\n",
       "      <td>0.429802</td>\n",
       "      <td>-0.872912</td>\n",
       "      <td>-0.339984</td>\n",
       "      <td>-0.171954</td>\n",
       "      <td>0.854678</td>\n",
       "      <td>-0.788994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_ftu</th>\n",
       "      <td>-0.997431</td>\n",
       "      <td>0.547694</td>\n",
       "      <td>-0.183411</td>\n",
       "      <td>-0.288991</td>\n",
       "      <td>-0.375861</td>\n",
       "      <td>-0.356187</td>\n",
       "      <td>0.433200</td>\n",
       "      <td>-0.285618</td>\n",
       "      <td>-0.122269</td>\n",
       "      <td>-0.676739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465353</td>\n",
       "      <td>0.481015</td>\n",
       "      <td>0.268942</td>\n",
       "      <td>-0.838261</td>\n",
       "      <td>0.671298</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.190407</td>\n",
       "      <td>0.265288</td>\n",
       "      <td>-0.391407</td>\n",
       "      <td>-0.659839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_qvc</th>\n",
       "      <td>-0.147522</td>\n",
       "      <td>-0.402608</td>\n",
       "      <td>-0.315536</td>\n",
       "      <td>-0.511516</td>\n",
       "      <td>0.516339</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.071008</td>\n",
       "      <td>0.604673</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>0.368689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417015</td>\n",
       "      <td>0.603839</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.530540</td>\n",
       "      <td>0.296515</td>\n",
       "      <td>-0.220551</td>\n",
       "      <td>0.491672</td>\n",
       "      <td>-0.762185</td>\n",
       "      <td>0.873178</td>\n",
       "      <td>-0.402150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_lsf</th>\n",
       "      <td>-0.266993</td>\n",
       "      <td>0.303426</td>\n",
       "      <td>0.898675</td>\n",
       "      <td>0.776627</td>\n",
       "      <td>-0.076705</td>\n",
       "      <td>0.251014</td>\n",
       "      <td>0.350783</td>\n",
       "      <td>0.148486</td>\n",
       "      <td>-0.297146</td>\n",
       "      <td>0.228995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416483</td>\n",
       "      <td>0.689567</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>0.414486</td>\n",
       "      <td>0.597038</td>\n",
       "      <td>-0.641432</td>\n",
       "      <td>0.481483</td>\n",
       "      <td>0.751060</td>\n",
       "      <td>-0.971406</td>\n",
       "      <td>0.064329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene0     gene1     gene2     gene3     gene4     gene5     gene6  \\\n",
       "A_1_kky  0.565431 -0.339680  0.727901  0.156712  0.567214  0.854648 -0.912212   \n",
       "A_1_yjn  0.454328 -0.703011 -0.196407  0.414263 -0.212149 -0.475095  0.768395   \n",
       "A_1_ftu -0.997431  0.547694 -0.183411 -0.288991 -0.375861 -0.356187  0.433200   \n",
       "A_1_qvc -0.147522 -0.402608 -0.315536 -0.511516  0.516339  0.566360  0.071008   \n",
       "A_1_lsf -0.266993  0.303426  0.898675  0.776627 -0.076705  0.251014  0.350783   \n",
       "\n",
       "            gene7     gene8     gene9    ...       gene40    gene41    gene42  \\\n",
       "A_1_kky  0.109724  0.651533  0.056977    ...     0.978305 -0.888512 -0.391051   \n",
       "A_1_yjn  0.798914  0.464159  0.863646    ...    -0.673128  0.216370  0.264719   \n",
       "A_1_ftu -0.285618 -0.122269 -0.676739    ...     0.465353  0.481015  0.268942   \n",
       "A_1_qvc  0.604673  0.033551  0.368689    ...     0.417015  0.603839  0.000614   \n",
       "A_1_lsf  0.148486 -0.297146  0.228995    ...     0.416483  0.689567  0.155130   \n",
       "\n",
       "           gene43    gene44    gene45    gene46    gene47    gene48    gene49  \n",
       "A_1_kky -0.993740 -0.219221  0.131645  0.409954 -0.801225 -0.842967  0.366684  \n",
       "A_1_yjn  0.843114  0.429802 -0.872912 -0.339984 -0.171954  0.854678 -0.788994  \n",
       "A_1_ftu -0.838261  0.671298  0.771700  0.190407  0.265288 -0.391407 -0.659839  \n",
       "A_1_qvc  0.530540  0.296515 -0.220551  0.491672 -0.762185  0.873178 -0.402150  \n",
       "A_1_lsf  0.414486  0.597038 -0.641432  0.481483  0.751060 -0.971406  0.064329  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transpose data\n",
    "workingdata = data.transpose()\n",
    "workingdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=workingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size):\n",
    "    rng = np.random\n",
    "    #perturbagens, profiles in each perturbagen, dimension of each profile\n",
    "    n_classes, n_examples, dimx, dimy = 25, 40, 50, 1 \n",
    "    \n",
    "    # randomly sample several classes to use in the batch\n",
    "    perturbagens = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
    "    \n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs=[np.zeros((batch_size, dimx)) for i in range(2)]\n",
    "    \n",
    "    # initialize vector for the targets\n",
    "    targets=np.zeros((batch_size,))\n",
    "    \n",
    "    # make one half of it '1's, so 2nd half of batch has same class\n",
    "    targets[batch_size//2:] = 1\n",
    "    #print(perturbagens)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        pert = perturbagens[i]\n",
    "        idx_1 = rng.randint(0, n_examples)\n",
    "        #print(pert, idx_1)\n",
    "        #print(X.iloc[n_examples*(pert-1)+idx_1,:].shape)\n",
    "        \n",
    "        pairs[0][i,:] = X.iloc[n_examples*(pert-1)+idx_1,:]#.values.reshape(dimx,dimy)\n",
    "        #print(pairs[0].shape)\n",
    "        idx_2 = rng.randint(0, n_examples)\n",
    "        \n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        pert2=pert\n",
    "        if i < batch_size // 2:\n",
    "            pert2 = rng.choice(list(range(pert)) + list(range(pert+1, n_classes)))\n",
    "\n",
    "        pairs[1][i,:] = X.iloc[n_examples*(pert2-1)+idx_1,:]#.values.reshape(dimx,dimy)\n",
    "\n",
    "    return np.asarray(pairs), np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 50)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, t = get_batch(10)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(batch_size, s=\"train\"):\n",
    "    \"\"\"\n",
    "    a generator for batches, so model.fit_generator can be used.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size,s)\n",
    "        yield (pairs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_oneshot_task( N):\n",
    "    rng = np.random\n",
    "    n_classes, n_examples, dimx, dimy = 25, 40, 50, 1 \n",
    "    \n",
    "    indices = rng.randint(0, n_examples,size=(N,))\n",
    "    perturbagens = rng.choice(range(n_classes),size=(N,),replace=False)   \n",
    "    true_category = perturbagens[0]\n",
    "    \n",
    "    ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "    \n",
    "    test_image = np.asarray([X.iloc[(true_category*n_examples)+ex1]]*N)\n",
    "    \n",
    "    support_set = np.asarray(X.iloc[perturbagens*n_examples+indices,:])\n",
    "    support_set[0,:] = X.iloc[(true_category*n_examples+ex2)]\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    pairs = [test_image,support_set]\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p,t = make_oneshot_task(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_oneshot(model, N, k,verbose = 0):\n",
    "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "    percent_correct = (100.0 * n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_neighbour_correct(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "  \n",
    "def test_nn_accuracy(N_ways,n_trials):\n",
    "    \"\"\"Returns accuracy of NN approach \"\"\"\n",
    "    print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = make_oneshot_task(N_ways,\"val\")\n",
    "        correct = nearest_neighbour_correct(pairs,targets)\n",
    "        n_right += correct\n",
    "    return 100.0 * n_right / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 50\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "\n",
    "def create_network(n_dense=6,\n",
    "                   dense_units=16,\n",
    "                   activation='selu',\n",
    "                   dropout=AlphaDropout,\n",
    "                   dropout_rate=0.1,\n",
    "                   kernel_initializer='lecun_normal',\n",
    "                   optimizer='adam',\n",
    "                   num_classes=1,\n",
    "                   max_words=max_words):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_units, input_shape=(max_words,),\n",
    "                    kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(dropout(dropout_rate))\n",
    "\n",
    "    for i in range(n_dense - 1):\n",
    "        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(dropout(dropout_rate))\n",
    "\n",
    "    #model.add(Dense(num_classes))\n",
    "    #model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = {\n",
    "    'n_dense': 10,\n",
    "    'dense_units': 16,\n",
    "    'activation': 'selu',\n",
    "    'dropout': AlphaDropout,\n",
    "    'dropout_rate': 0.1,\n",
    "    'kernel_initializer': 'lecun_normal',\n",
    "    'optimizer': 'sgd',\n",
    "    'num_classes':40\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_model = create_network(**network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ManDist(Layer):\n",
    "    \n",
    "    # initialize the layer, No need to include inputs parameter!\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDist, self).__init__(**kwargs)\n",
    "\n",
    "    # input_shape will automatic collect input shapes to build layer\n",
    "    def build(self, input_shape):\n",
    "        super(ManDist, self).build(input_shape)\n",
    "\n",
    "    # This is where the layer's logic lives.\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True)\n",
    "        return self.result\n",
    "\n",
    "    # return output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_input = Input(shape=(max_words,))\n",
    "right_input = Input(shape=(max_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
    "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])\n",
    "model.compile(loss=contrastive_loss, optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = './weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 0.028206419944763184 mins\n",
      "Train Loss: [1.3858105, 0.2]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 5.2% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 5.2, previous best: -1\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 400 iterations: 0.06502366860707601 mins\n",
      "Train Loss: [0.8624792, 0.3]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 6.4% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 6.4, previous best: 5.2\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 600 iterations: 0.10598047971725463 mins\n",
      "Train Loss: [1.4148902, 0.1]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 5.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 800 iterations: 0.14987645149230958 mins\n",
      "Train Loss: [1.1376113, 0.4]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 4.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1000 iterations: 0.19406606753667197 mins\n",
      "Train Loss: [0.42311773, 0.6]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 5.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1200 iterations: 0.2362156828244527 mins\n",
      "Train Loss: [0.31446558, 0.3]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 4.4% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1400 iterations: 0.2730349818865458 mins\n",
      "Train Loss: [0.30816382, 0.6]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 6.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 6.8, previous best: 6.4\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1600 iterations: 0.30979461669921876 mins\n",
      "Train Loss: [0.3877183, 0.6]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 3.6% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1800 iterations: 0.3465114672978719 mins\n",
      "Train Loss: [0.3397389, 0.6]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 2.8% 20 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2000 iterations: 0.3833767334620158 mins\n",
      "Train Loss: [0.35477018, 0.8]\n",
      "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 6.8% 20 way one-shot learning accuracy \n",
      "\n",
      "Current best: 6.8, previous best: 6.8\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "# Hyper parameters\n",
    "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
    "batch_size = 10\n",
    "n_iter = 2000 # No. of training iterations\n",
    "N_way = 20 # how many classes for testing one-shot tasks\n",
    "n_val = 250 # how many one-shot tasks to validate on\n",
    "best = -1\n",
    "\n",
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs,targets) = get_batch(batch_size)\n",
    "    loss = model.train_on_batch([inputs[0],inputs[1]], targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        #model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
