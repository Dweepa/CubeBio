{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "plot = True\n",
    "\n",
    "\n",
    "def create_network(n_dense=6,\n",
    "                   dense_units=16,\n",
    "                   activation='selu',\n",
    "                   dropout=AlphaDropout,\n",
    "                   dropout_rate=0.1,\n",
    "                   kernel_initializer='lecun_normal',\n",
    "                   optimizer='adam',\n",
    "                   num_classes=1,\n",
    "                   max_words=max_words):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_units, input_shape=(max_words,),\n",
    "                    kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(dropout(dropout_rate))\n",
    "\n",
    "    for i in range(n_dense - 1):\n",
    "        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_network1(n_dense=6,\n",
    "                   dense_units=16,\n",
    "                   activation='selu',\n",
    "                   dropout=AlphaDropout,\n",
    "                   dropout_rate=0.1,\n",
    "                   kernel_initializer='lecun_normal',\n",
    "                   optimizer='adam',\n",
    "                   num_classes=1,\n",
    "                   max_words=max_words):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_units, input_shape=(max_words,),\n",
    "                    kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(dropout(dropout_rate))\n",
    "\n",
    "    for i in range(n_dense - 1):\n",
    "        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network2 = {\n",
    "    'n_dense': 6,\n",
    "    'dense_units': 16,\n",
    "    'activation': 'selu',\n",
    "    'dropout': AlphaDropout,\n",
    "    'dropout_rate': 0.1,\n",
    "    'kernel_initializer': 'lecun_normal',\n",
    "    'optimizer': 'sgd'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
    "                                                         test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network 2\n"
     ]
    }
   ],
   "source": [
    "print('Building network 2')\n",
    "model2 = create_network(num_classes=num_classes, **network2)\n",
    "\n",
    "history_model2 = model2.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=0, validation_split=0.1)\n",
    "\n",
    "score_model2 = model2.evaluate(x_test,\n",
    "                               y_test,\n",
    "                               batch_size=batch_size,\n",
    "                               verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = create_network1(num_classes=num_classes, **network2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network 2 results\n",
      "Hyperparameters: {'n_dense': 6, 'dense_units': 16, 'activation': 'selu', 'dropout': <class 'keras.layers.noise.AlphaDropout'>, 'dropout_rate': 0.1, 'kernel_initializer': 'lecun_normal', 'optimizer': 'sgd'}\n",
      "Test score: 1.642313003327734\n",
      "Test accuracy: 0.6268922529471102\n"
     ]
    }
   ],
   "source": [
    "print('Network 2 results')\n",
    "print('Hyperparameters:', network2)\n",
    "print('Test score:', score_model2[0])\n",
    "print('Test accuracy:', score_model2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from tensorflow.python.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import itertools\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Embedding, Lambda,LSTM, GRU, Conv1D, Conv2D, GlobalMaxPool1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ManDist(Layer):\n",
    "    \"\"\"\n",
    "    Keras Custom Layer that calculates Manhattan Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the layer, No need to include inputs parameter!\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDist, self).__init__(**kwargs)\n",
    "\n",
    "    # input_shape will automatic collect input shapes to build layer\n",
    "    def build(self, input_shape):\n",
    "        super(ManDist, self).build(input_shape)\n",
    "\n",
    "    # This is where the layer's logic lives.\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "        return self.result\n",
    "\n",
    "    # return output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_input = Input(shape=(max_words,))\n",
    "right_input = Input(shape=(max_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "gpus = 2\n",
    "batch_size = 1024 * gpus\n",
    "n_epoch = 20\n",
    "n_hidden = 50\n",
    "\n",
    "# Define the shared model\n",
    "x = Sequential()\n",
    "x.add(Embedding(46,10))\n",
    "x.add(LSTM(n_hidden))\n",
    "x.add(Dropout(0.1))\n",
    "shared_model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'- embedding layer is required\n",
    "#Node error -> from keras not from tf.python.keras\n",
    "#Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'. ->\n",
    "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
    "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 46)           18158       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist_2 (ManDist)            (None, 1)            0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 18,158\n",
      "Trainable params: 18,158\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 16)                16016     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_43 (AlphaDropo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_44 (AlphaDropo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_45 (AlphaDropo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_46 (AlphaDropo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_47 (AlphaDropo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_48 (AlphaDropo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 46)                782       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 46)                0         \n",
      "=================================================================\n",
      "Total params: 18,158\n",
      "Trainable params: 18,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.summary()\n",
    "shared_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected man_dist_2 to have shape (1,) but got array with shape (46,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-2938b31cf0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m malstm_trained = model.fit([x_train,x_train], y_train,\n\u001b[0;32m----> 3\u001b[0;31m                            batch_size=batch_size, epochs=n_epoch, verbose=1)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtraining_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time finished.\\n%d epochs in %12.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_end_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected man_dist_2 to have shape (1,) but got array with shape (46,)"
     ]
    }
   ],
   "source": [
    "training_start_time = time()\n",
    "malstm_trained = model.fit([x_train,x_train], y_train,\n",
    "                           batch_size=batch_size, epochs=n_epoch, verbose=1)\n",
    "training_end_time = time()\n",
    "print(\"Training time finished.\\n%d epochs in %12.2f\" % (n_epoch,training_end_time - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
